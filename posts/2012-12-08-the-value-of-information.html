---
title: The Value of Information
tags: maths
---

<p>
"Test everything" is a PPC and SEO truism that everyone says is
important but that no one actually does. In PPC at least most people
test some things (I'm not sure if this can be said of most SEOs) but
anyone who sets out to test everything is on the fast track to
analysis paralysis. So if no one is testing everything then what are
they testing? Based on my experience the following list comes close:
</p>
<ol class="org-ol">
<li>Things that are easy to test e.g. ad texts
</li>
<li>Things that could have a big impact but for which the results are
uncertain e.g. conversion optimiser bidding
</li>
<li>Testing to prove a point to (or for) a HIPPO. Like most, I have great faith
in test results for changing people's minds. Like most, I find that
this never works as well as expected, even when the results go my
way.
</li>
</ol>

<p>
Basically, people test things where the cost of testing is low or
where the expected impact of new knowledge is high.
</p>

<div id="outline-container-sec-1" class="outline-2">
<h2 id="sec-1"><span class="section-number-2">1</span> The Expected Impact of New Knowledge</h2>
<div class="outline-text-2" id="text-1">
<p>
What exactly do I mean by the expected impact of new knowledge? I will
try and explain with an example.
</p>

<p>
I am extremely confident that separating the search and content
networks into different campaigns is a good thing. Learning otherwise
wouldn't make a big difference to how I manage accounts because I'd
want to separate these two impression types anyway for reporting
purposes. So if I were to test this out I'd be running a test that
will almost certainly confirm what I already know and in the unlikely
event of a combined campaign performing equally well it wouldn't
change any of my actions. This is an example of knowledge with low
impact.
</p>

<p>
Alternatively consider using the conversion optimiser bid management
tool. I have had mixed results with this in the past, sometimes it
works well and sometimes it completely bombs. So I am much less
certain about the likely outcome of any test. In the cases where the
conversion optimiser works it saves a lot of time and can increase the
number of conversions. My initial levels of uncertainty combined with
the high impact outcome make this test worth running; if I don't test
then I could make a bad decision.
</p>
</div>
</div>

<div id="outline-container-sec-2" class="outline-2">
<h2 id="sec-2"><span class="section-number-2">2</span> Some More Examples</h2>
<div class="outline-text-2" id="text-2">
<p>
If you can correctly guess the outcome of a coin flip then I will pay
you $1. You also have the opportunity to perform a simple test; pay my
assistant $0.75 and she will tell you (with 100% accuracy - no funny
business) which way the coin landed.
</p>

<p>
Without testing your expected return is $0.50 per flip. With the test,
you'll get the answer right each time but you can only expect to earn
$0.25 each flip.
</p>

<p>
In this case the test costs too much given the value of the
information it provides. In a situation where you have a lower
probability of being correct then the information is relatively more
valuable. For example if the setup was exactly the same except you had
to tell me the score from rolling a six sided dice then paying my
assistant $0.75 would be worthwhile.
</p>

<p>
For another example suppose I ask you to tell me whether or not the
value of a dice roll is greater than one. My assistant offers to tell
you whether or not the number is even. How much should you pay for
this information?
</p>

<p>
Without any extra knowledge, you will say that the score is greater
than one and expect to earn $(5/6)=$0.83 per turn.
</p>

<p>
If you know the number is even then you know the number is certain to be
greater than one. If the number is odd then it is greater than one
with probability 2/3 (because five and three are the only odd dice
numbers greater than one). So either way, the rational thing to do is
to guess that the number is greater than one. Hence my assistant's
information is valueless to you and you should not pay for it.
</p>
</div>
</div>

<div id="outline-container-sec-3" class="outline-2">
<h2 id="sec-3"><span class="section-number-2">3</span> When Not to Test</h2>
<div class="outline-text-2" id="text-3">
<p>
Probabilities in the real world are never so easy to calculate as in
the examples. Often it will be impossible (or the opportunity cost
will be too high). So instead I offer the following rules for when not
to test:
</p>
<ol class="org-ol">
<li>When you are highly confident in what the outcome will
be. Particularly when a contradictory result will make you doubt
the test rather than your preconceptions (I am like this with
psychics)
</li>
<li>When the outcome will not make any difference to your actions
i.e. you'll do the same thing either way
</li>
<li>When the difference in performance between the two alternatives
being tested is likely to be smaller than the cost of running and
analysing the test.
</li>
</ol>

<p>
All of these concepts could do with being more precisely
defined. Perhaps I will attempt that in a future post.
</p>
</div>
</div>
